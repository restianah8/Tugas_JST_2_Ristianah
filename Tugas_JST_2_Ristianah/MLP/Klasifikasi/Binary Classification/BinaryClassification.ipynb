{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BinaryClassification.ipynb","provenance":[{"file_id":"1uxSMwKFo4R1StJ3rfAGJfmrRlKIQC4Yk","timestamp":1621600535719}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8Z0KV4ninwV","executionInfo":{"status":"ok","timestamp":1622013382321,"user_tz":-420,"elapsed":31559,"user":{"displayName":"Risti Anah","photoUrl":"","userId":"10333828037251958874"}},"outputId":"4c19c30a-030e-4847-d947-9b04dca64c49"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7NyqQuhj6Vw","executionInfo":{"status":"ok","timestamp":1622013389521,"user_tz":-420,"elapsed":3255,"user":{"displayName":"Risti Anah","photoUrl":"","userId":"10333828037251958874"}}},"source":["# mlp for binary classification\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kgc6fvKkGrY","executionInfo":{"status":"ok","timestamp":1622013430698,"user_tz":-420,"elapsed":385,"user":{"displayName":"Risti Anah","photoUrl":"","userId":"10333828037251958874"}},"outputId":"7a570f49-3cc6-4832-8870-a61bc3704fa1"},"source":["path = '/content/drive/MyDrive/Tugas_JST_2_Ristianah/MLP/Klasifikasi/Binary Classification/ionosphere.csv'\n","df = read_csv(path, header=None)\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","# determine the number of input features\n","n_features = X_train.shape[1]\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(235, 34) (116, 34) (235,) (116,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew827nXrzSDi","executionInfo":{"status":"ok","timestamp":1622013524358,"user_tz":-420,"elapsed":6264,"user":{"displayName":"Risti Anah","photoUrl":"","userId":"10333828037251958874"}},"outputId":"c84ec926-7027-4f87-944b-4c40e50985cb"},"source":["# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)\n","model_url = '/content/drive/MyDrive/Tugas_JST_Ristianah/MLP/Klasifikasi/Binary Classification/klasifikasi_binary.h5'\n","model.save(model_url)\n","print(\"Saved\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","8/8 [==============================] - 1s 3ms/step - loss: 0.8658 - accuracy: 0.4043\n","Epoch 2/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.7807 - accuracy: 0.4255\n","Epoch 3/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.4128\n","Epoch 4/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5191\n","Epoch 5/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.7277\n","Epoch 6/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7830\n","Epoch 7/150\n","8/8 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7830\n","Epoch 8/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7745\n","Epoch 9/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7787\n","Epoch 10/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7787\n","Epoch 11/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7787\n","Epoch 12/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7915\n","Epoch 13/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8043\n","Epoch 14/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8043\n","Epoch 15/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8213\n","Epoch 16/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8298\n","Epoch 17/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8340\n","Epoch 18/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8340\n","Epoch 19/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8426\n","Epoch 20/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8426\n","Epoch 21/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8426\n","Epoch 22/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8596\n","Epoch 23/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8809\n","Epoch 24/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8936\n","Epoch 25/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8894\n","Epoch 26/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8936\n","Epoch 27/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.9021\n","Epoch 28/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.9064\n","Epoch 29/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.9106\n","Epoch 30/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.9106\n","Epoch 31/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9149\n","Epoch 32/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.9191\n","Epoch 33/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.9191\n","Epoch 34/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.9149\n","Epoch 35/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9149\n","Epoch 36/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9234\n","Epoch 37/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.9234\n","Epoch 38/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.2446 - accuracy: 0.9234\n","Epoch 39/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.2393 - accuracy: 0.9234\n","Epoch 40/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9234\n","Epoch 41/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9234\n","Epoch 42/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9234\n","Epoch 43/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9234\n","Epoch 44/150\n","8/8 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9277\n","Epoch 45/150\n","8/8 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9277\n","Epoch 46/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9277\n","Epoch 47/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9277\n","Epoch 48/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9277\n","Epoch 49/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9277\n","Epoch 50/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9277\n","Epoch 51/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9277\n","Epoch 52/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9362\n","Epoch 53/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9362\n","Epoch 54/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9362\n","Epoch 55/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1764 - accuracy: 0.9362\n","Epoch 56/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9362\n","Epoch 57/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9362\n","Epoch 58/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9404\n","Epoch 59/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9447\n","Epoch 60/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9447\n","Epoch 61/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9489\n","Epoch 62/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9489\n","Epoch 63/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9532\n","Epoch 64/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9489\n","Epoch 65/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9489\n","Epoch 66/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9489\n","Epoch 67/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9532\n","Epoch 68/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9532\n","Epoch 69/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9574\n","Epoch 70/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9532\n","Epoch 71/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9702\n","Epoch 72/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9702\n","Epoch 73/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9702\n","Epoch 74/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9702\n","Epoch 75/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9702\n","Epoch 76/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9702\n","Epoch 77/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9702\n","Epoch 78/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9702\n","Epoch 79/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9702\n","Epoch 80/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9745\n","Epoch 81/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9702\n","Epoch 82/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9745\n","Epoch 83/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9745\n","Epoch 84/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9745\n","Epoch 85/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9745\n","Epoch 86/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9745\n","Epoch 87/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9745\n","Epoch 88/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9745\n","Epoch 89/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9745\n","Epoch 90/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9745\n","Epoch 91/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9745\n","Epoch 92/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9745\n","Epoch 93/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9787\n","Epoch 94/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9787\n","Epoch 95/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9787\n","Epoch 96/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.9830\n","Epoch 97/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9830\n","Epoch 98/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9830\n","Epoch 99/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9830\n","Epoch 100/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9787\n","Epoch 101/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9787\n","Epoch 102/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9787\n","Epoch 103/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9830\n","Epoch 104/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9830\n","Epoch 105/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9830\n","Epoch 106/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9830\n","Epoch 107/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9830\n","Epoch 108/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9830\n","Epoch 109/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9872\n","Epoch 110/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9872\n","Epoch 111/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9872\n","Epoch 112/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9872\n","Epoch 113/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9872\n","Epoch 114/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9872\n","Epoch 115/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9872\n","Epoch 116/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9872\n","Epoch 117/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9872\n","Epoch 118/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9872\n","Epoch 119/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9872\n","Epoch 120/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9872\n","Epoch 121/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9872\n","Epoch 122/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9872\n","Epoch 123/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9872\n","Epoch 124/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9872\n","Epoch 125/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9872\n","Epoch 126/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9872\n","Epoch 127/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9872\n","Epoch 128/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9872\n","Epoch 129/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9872\n","Epoch 130/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9872\n","Epoch 131/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9872\n","Epoch 132/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9872\n","Epoch 133/150\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9872\n","Epoch 134/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9872\n","Epoch 135/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9872\n","Epoch 136/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9872\n","Epoch 137/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9872\n","Epoch 138/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9872\n","Epoch 139/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9872\n","Epoch 140/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9872\n","Epoch 141/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9872\n","Epoch 142/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9872\n","Epoch 143/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9872\n","Epoch 144/150\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9872\n","Epoch 145/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9872\n","Epoch 146/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9872\n","Epoch 147/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9872\n","Epoch 148/150\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9872\n","Epoch 149/150\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9872\n","Epoch 150/150\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9872\n","Saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NHIJCYZqkvHJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622013540987,"user_tz":-420,"elapsed":568,"user":{"displayName":"Risti Anah","photoUrl":"","userId":"10333828037251958874"}},"outputId":"ca2476c1-c29b-4313-81e0-19c97257aa06"},"source":["loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Test Accuracy: 0.914\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvtHFnd40dCQ","executionInfo":{"status":"ok","timestamp":1622013547053,"user_tz":-420,"elapsed":734,"user":{"displayName":"Risti Anah","photoUrl":"","userId":"10333828037251958874"}},"outputId":"8b48d0d3-ca7b-4df4-ec15-9ba63548b589"},"source":["# make a prediction\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Predicted: 0.982\n"],"name":"stdout"}]}]}